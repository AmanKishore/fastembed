{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9dbcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.pipelines import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import AutoOptimizationConfig, ORTModelForFeatureExtraction, ORTOptimizer\n",
    "from optimum.onnxruntime.configuration import OptimizationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd40618",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a65856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and export the model to the ONNX format\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "save_dir = \"fast-all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451dbd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(model_id, export=True)\n",
    "\n",
    "# Remove all existing files in the save_dir using Path.unlink()\n",
    "save_dir = Path(save_dir)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "for p in save_dir.iterdir():\n",
    "    p.unlink()\n",
    "\n",
    "# Load the optimization configuration detailing the optimization we wish to apply\n",
    "optimization_config = AutoOptimizationConfig.O3()\n",
    "optimizer = ORTOptimizer.from_pretrained(model)\n",
    "\n",
    "optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config, use_external_data_format=True)\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(save_dir)\n",
    "\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "# model.save_pretrained(save_dir)\n",
    "# model.push_to_hub(\"new_path_for_directory\", repository_id=\"my-onnx-repo\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22005e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_embed = pipeline(\"feature-extraction\", model=\"sentence-transformers/all-MiniLM-L6-v2\", accelerator=\"ort\")\n",
    "question = \"What's my name?\" * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_quant_embed = pipeline(\"feature-extraction\", model=model, accelerator=\"ort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72aba5",
   "metadata": {},
   "source": [
    "# Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b881152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "pred = onnx_quant_embed(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = len(question)\n",
    "print(f\"Speed: {(chars*10^3)/16.5} char/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1daf8",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "embeddings = hf_model.encode(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = len(question)\n",
    "print(f\"Speed: {(chars*10^3)/26.3} char/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "\n",
    "def compress(directory_path):\n",
    "    output_filename = directory_path.name + \".tar.gz\"\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(directory_path, arcname=os.path.basename(directory_path))\n",
    "    return output_filename\n",
    "\n",
    "\n",
    "compressed_file_name = compress(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "def upload(bucket_name, source_file_path):\n",
    "    storage_client = storage.Client(project=\"main\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(os.path.basename(source_file_path))\n",
    "\n",
    "    blob.upload_from_filename(source_file_path)\n",
    "\n",
    "    print(f\"File {source_file_path} uploaded to {bucket_name}.\")\n",
    "\n",
    "\n",
    "upload(\"qdrant-fastembed\", compressed_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731554f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the directory and compressed file\n",
    "!rm -rvf {save_dir}\n",
    "!rm -vf {save_dir}.tar.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
