{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f159fb4",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "Here you will learn how to use the fastembed package to embed your data into a vector space. The package is designed to be easy to use and fast. It is built on top of the [ONNX](https://onnx.ai/) standard, which allows for fast inference on a variety of hardware (called Runtimes in ONNX). \n",
    "\n",
    "## Installation\n",
    "\n",
    "To get started, install the fastembed package with pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b5612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: fastembed in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (0.0.2)\n",
      "Requirement already satisfied: onnxruntime<2.0.0,>=1.15.1 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from fastembed) (1.15.1)\n",
      "Requirement already satisfied: onnxruntime-silicon<2.0.0,>=1.15.0 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from fastembed) (1.15.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from fastembed) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.14.0,>=0.13.3 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from fastembed) (0.13.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from fastembed) (4.65.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from onnxruntime<2.0.0,>=1.15.1->fastembed) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from onnxruntime<2.0.0,>=1.15.1->fastembed) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from onnxruntime<2.0.0,>=1.15.1->fastembed) (1.24.4)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from onnxruntime<2.0.0,>=1.15.1->fastembed) (23.1)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from onnxruntime<2.0.0,>=1.15.1->fastembed) (4.23.4)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from onnxruntime<2.0.0,>=1.15.1->fastembed) (1.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->fastembed) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->fastembed) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->fastembed) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->fastembed) (2023.5.7)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from coloredlogs->onnxruntime<2.0.0,>=1.15.1->fastembed) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Caskroom/miniconda/base/envs/fst/lib/python3.9/site-packages (from sympy->onnxruntime<2.0.0,>=1.15.1->fastembed) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastembed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b503b",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "The fastembed package is designed to be easy to use. The main class is the `Embedding` class. It takes a list of strings as input and returns a list of vectors as output. The `Embedding` class is initialized with a model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8349e72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "from fastembed.embedding import FlagEmbedding as Embedding\n",
    "\n",
    "# Example list of documents to encode\n",
    "documents: List[str] = [\n",
    "    \"Hello, World!\",\n",
    "    \"This is an example document.\",\n",
    "    \"fastembed is supported by and maintained by Qdrant.\",\n",
    "]\n",
    "# Initialize the DefaultEmbedding class with the desired parameters\n",
    "embedding_model = Embedding(model_name=\"BAAI/bge-small-en\", max_length=512)\n",
    "embeddings: List[np.ndarray] = list(embedding_model.encode(documents)) # notice that we are casting the generator to a list\n",
    "\n",
    "print(embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c49ae50",
   "metadata": {},
   "source": [
    "## Explanation of what is happening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf4b76",
   "metadata": {},
   "source": [
    "Importing the required classes and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a6f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "from fastembed.embedding import FlagEmbedding as Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd03a71",
   "metadata": {},
   "source": [
    "Notice that we are using the FlagEmbedding -- which is state of the Art and beats OpenAI's Embedding by a large margin. \n",
    "\n",
    "## Prepare your Documents\n",
    "You can define a list of documents that you'd like to encode. These can be sentences, paragraphs, or even entire documents. \n",
    "\n",
    "### Format of the List:\n",
    "1. List of Strings: Your documents must be in a list, and each document must be a string.\n",
    "2. For Retrieval Tasks: If you're working with queries and passages, you can add special labels to them:\n",
    "- **Queries**: Add \"query:\" at the beginning of each query string.\n",
    "- **Passages**: Add \"passage:\" at the beginning of each passage string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "145a56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example list of documents to encode\n",
    "documents: List[str] = [\n",
    "    \"query: Hello, World!\",\n",
    "    \"query: This is an example document.\",\n",
    "    \"passage: fastembed is supported by and maintained by Qdrant.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb3cc87",
   "metadata": {},
   "source": [
    "## Load the Embedding Model Weights\n",
    "Next, initialize the Embedding class with the desired parameters. Here, \"BAAI/bge-small-en\" is the pre-trained model name, and max_length=512 is the maximum token length for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "272c8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DefaultEmbedding class with the desired parameters\n",
    "embedding_model = Embedding(model_name=\"BAAI/bge-small-en\", max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549d501",
   "metadata": {},
   "source": [
    "## Embed your Documents\n",
    "\n",
    "Use the encode method of the embedding model to transform the documents into a List of np.array. The method returns a generator, so we cast it to a list to get the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8013eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings: List[np.ndarray] = list(embedding_model.encode(documents)) # notice that we are casting the generator to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b5a6ad",
   "metadata": {},
   "source": [
    "You can print the shape of the embeddings to understand their dimensions. Typically, the shape will indicate the number of dimensions in the encoded vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d8c8e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings[0].shape) # (768,) or similar output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
